---
title: "Practical 10"
subtitle: "Generalized Linear Model"
author: "SÃ¶ren Michallek"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: TRUE
    toc_depth: 2
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(GLMsData)
library(tidyverse)
```

------------------------------------------------------------------------

In this practical, we will compare the estimates of the linear and the generalized linear model when the dependent variable is either a count or dichotomous variable. The data sets for this practical are `galapagos` and `lungcap` from the package `GLMsData`. To load the data into workspace you need to use the function `data()`.

# 1 Count variables

The data set `galapagos` contains the variable `PlantEnd` with a count of the endemic plants on each of the 29 islands. Check the `galapagos` help page for an explanation of the other variables. In this exercise, we will predict the number of endemic plant species using the variables `Area`, `Elevation`, `Nearest`, and `Adjacent` as predictors.

a.  Display the summary of the data set `galapagos`, and check the distributions of the dependent variable `PlantEnd` and the four predictors `Area`, `Elevation`, `Nearest`, and `Adjacent`.

```{r}
data(galapagos)
summary(galapagos)

galapagos %>%
  select(PlantEnd, Area, Elevation, Nearest, Adjacent) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram() +
    theme_minimal()
```

b.  Select the variables `PlantEnd`, `Area`, `Elevation`, `Nearest`, and `Adjacent`. Apply a normalizing logarithmic transformation to the four predictors of `PlantEnd`, and then standardize them. Save this new data set as `galapagos_`.

```{r}
galapagos_ <- galapagos %>%
  select(PlantEnd, Area, Elevation, Nearest, Adjacent) %>%
  mutate(Area      = scale(log(Area)),
         Elevation = scale(log(Elevation)),
         Nearest   = scale(log(Nearest)),
         Adjacent  = scale(log(Adjacent)))
```

## 1.1 Linear model

We will first treat the `PlantEnd` as a continuous variable with a distribution from the Gaussian family.

a.  Fit the generalized linear model `PlandEnd ~ Area` with `family = "gaussian"`; display its summary, and interpret the parameter estimates.

```{r}
summary(glm(PlantEnd ~ Area, family = "gaussian", galapagos_))
```

The model with `Area` is significant. the distribution is biased to the left. An increase of 1 square kilometer in area means the number of endemic plant species increases by 23.3.

b.  Display a scatterplot with `Area` on the x-axis and `PlantEnd` on the y-axis, and include the linear regression line. Interpret the predicted values for the islands with small areas.

```{r, fig.asp = 1}
ggplot(galapagos_, aes(Area, PlantEnd)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "gaussian")) +
  theme_minimal()
```

Islands with smaller areas have fewer endemic plant species than islands with larger areas.

c.  Display and interpret the residual plots for the linear model.

```{r, fig.asp = 1}
par(mfrow = c(2, 2))

plot(glm(PlantEnd ~ Area, family = "gaussian", galapagos_))
```
Apart from the assumption of no influential outliers all other assumptions (Linearity, Normality, Heteroscedascity) are violated.

## 1.2 Poisson model

We will now treat `PlantEnd` as a count variable with a distribution from the Poisson family.

a.  Fit the same model as above, but now with `family = "poisson"`; display its summary and interpret the parameter estimates. What are the differences with the linear model?

```{r}
summary(glm(PlantEnd ~ Area, family = "poisson", galapagos_))
```

`Area` is a significant predictor for `PlantEnd` in the poisson model. With every increase in 1 square kilometer the number of endemic plants increases by 0.93. This is a weaker increase than in the previous model. In contrast to the previous model, this model does not seem skewed as the median is very close to 0.

b.  Display a scatterplot with `Area` on the x-axis and `PlantEnd` on the y-axis, and include the Poisson regression line (draw a line through the predicted counts). How do these predictions compare to those of the linear model?

```{r, fig.asp = 1}
ggplot(galapagos_, aes(Area, PlantEnd)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "poisson")) +
  theme_minimal()
```

The model has a bad fit.

## 1.3 Model selection

a.  Thus far we have only used `Area` as predictor, but we could also include `Elevation`, `Nearest`, and `Adjacent`. Use the `step()` function to find the most parsimonious main-effects model.

```{r}
fit <- glm(PlantEnd ~ 1, family = poisson, galapagos_)

step(fit, scope = PlantEnd ~ Area + Elevation + Adjacent + Nearest)
```

The last model which includes all predictors apart from `Elevation` is the most parsimonious model with the lowest AIC.

------------------------------------------------------------------------

# 2 Dichotomous variables

The data set `lungcap` contains data on four characteristics of smokers and non-smokers (check its help page for details). In this exercise, we will use these characteristics to predict the probability of being a smoker.

a.  Display the summary of the data, and check the variables for skew.

```{r fig.asp = 1}
data(lungcap)
summary(lungcap)

lungcap %>%
  select(Gender, Smoke) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_bar() +
    theme_minimal()
```


b.  Display a frequency table for the variable `Smoke` to see how many smokers and non-smokers there are in the data.

```{r}
table(lungcap$Smoke)
```


## 2.1 Linear model

We will start again by treating the variable `Smoke` as continuous with a distribution from the Gaussian family.

a.  Fit the generalized linear model `Smoke ~ Age` with the argument `family = "gaussian"`, and display and interpret its summary.

```{r}
summary(glm(Smoke ~ Age, family = gaussian, lungcap))
```
`Age` is a significant predictor of `Smoke`. The model is not biased in any direction as the median is close to 0.


b.  Display a scatterplot with `Age` on the x-axis and `Smoke` on the y-axis, and add the linear regression line regression line.

```{r fig.asp = 1}
ggplot(lungcap, aes(Age, Smoke)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_minimal()
```


c.  Display and interpret the diagnostic residual plots for the linear model.

```{r fig.asp = 1}
par(mfrow = c(2, 2))
plot(glm(Smoke ~ Age, family = gaussian, lungcap))
```

None of the assumptions tested by the diagnostic plots apart from the assumption of no influential outliers are met. This indicates that the data is not suited for analysis with a gaussian linear model.

## 2.2 Logistic regression model

We will now treat `Smoke` as a dichotomous variable with a Bernoulli distribution.

a.  Fit the logistic regression model `Smoke ~ Age`, and display and interpret its summary.

```{r}
summary(glm(Smoke ~ Age, family = binomial, lungcap))
```

`Age` is a significant predictor of `Smoke`. The model is not biased in any direction as the median is close to 0.

b.  Display a scatterplot with `Age` on the x-axis and `Smoke` on the y-axis. Add a line representing the probability of smoking predicted by the logistic regression model, and compare (the range of) the predicted values to those of the linear model.

```{r fig.asp = 1}
ggplot(lungcap, aes(Age, Smoke)) +
  geom_point() +
  geom_smooth(method = "glm", 
    method.args = list(family = "binomial")) +
  theme_minimal()
```

The linear model predicts values from below 0 to .5 for `Smoke` while the GLM predicts all values between 0 and 1 for `Smoke`, which makes more sense for a dichotomous variable.

## 2.3 Model selection

a.  Find the most parsimonious main-effects logistic regression model when all variables in `lungcap` are allowed to enter the model as predictors.

```{r}
fit <- glm(Smoke ~ ., lungcap, family = binomial)
step(fit, scope = list(lower = y ~ 1, upper = y ~ .), trace = 0)
```
The model with `Age` + `Gender` + `Ht` + `FEV` is the most parsimonious because it has the lowest AIC.

------------------------------------------------------------------------

End of practical
